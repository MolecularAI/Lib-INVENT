{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `lib-invent` environment. Navigate to the project directory and install:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate lib-invent`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Lib-INVENT`: Prior Training - teacher's forcing\n",
    "\n",
    "The purpose of this notebook is to demonstrate the process of setting up training of the prior capable of producing valid, ChEMBL-like SMILES strings. After it learns the syntax of the SMILES language, the prior is used in reinforcement learning.\n",
    "\n",
    "The datasets provided in the public repository include a traning dataset and a validation dataset. For details of the preprocessing, see the Lib-INVENT Datasets project repository and tutorials. The expected input format is a tab-separated file with entries on each line corresponding to scaffolds, decorations and complete compounds.\n",
    "\n",
    "To train the prior model, the required input is an initialised empty model along with the training and validation data.\n",
    "\n",
    "The state of the model is saved with a user-specified frequency during training, resulting in a sequence of models saved in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "project_directory = \"</path/to/project/directory>\"\n",
    "output_dir = \"<path/to/output/directory>\"\n",
    "empty_model_path = os.path.join(project_directory, \"tutorial/models/empty_model/model.empty\")\n",
    "training_set_path = os.path.join(project_directory, \"training_sets/chembl_train.smi\") \n",
    "validation_set_path = \"</path/to/validation/data>\" #same format as train data\n",
    "\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the configuration\n",
    "`Lib-INVENT` has an entry point that loads a specified `JSON` file on startup. `JSON` is a low-level data format that allows to specify a large number of parameters in a cascading fashion very quickly. The parameters are structured into *blocks* which can in turn contain blocks or simple values, such as *True* or *False*, strings and numbers. \n",
    "\n",
    "This notebook demonstrates the process of assembling an input `JSON` to pretrain the prior model. It details the purpose of each of the necessary blocks and suggests potential values of the parameters. Note, that while we will write out the configuration as a `JSON` file in the end, in `python` we handle the same information as a simple `dict`.\n",
    "\n",
    "At the highest level, the teacher's forcing input configuration consists of a two blocks. The string parameter `run_type` specifies the type of training or action to be performed by the model (e.g. reinforcement learning or compound sampling) while a second, large block specifies all the parameter necessary for performing this action. Depending on the running mode, this can include the specification of the scoring function, logging setup or training details such as the number of epochs and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"run_type\": \"transfer_learning\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assembly of the `parameters` block requires the specification of training parameters to be used in the training. First, paths to appropriate directories are given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"model_path\": empty_model_path,\n",
    "    \"training_set_path\": training_set_path,\n",
    "    \"output_path\":os.path.join(output_dir, \"trained\") ,\n",
    "    \"validation_sets_path\": validation_set_path,\n",
    "    \"logging_path\": os.path.join(output_dir, \"run.log\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other necessary parameters involve the set up of the run itself and logging. The \"do not change\" parameters are needed for development purposes only and should not be altered during standard model usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.update({\n",
    "    \"decoration_type\": \"single\", # Do not change\n",
    "    \"with_weights\": False,       # Do not change\n",
    "    \n",
    "    \"sample_size\": 10000,        # Relevant for logging\n",
    "    \"save_frequency\": 1,         # Frequency of saving of trained models\n",
    "    \"epochs\": 20,               \n",
    "    \"batch_size\": 256,          \n",
    "    \"clip_gradients\": 1.0,\n",
    "    \"collect_stats_frequency\": 1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, set up learning rate. LR scheduler is used, decreasing the LR by the factor `gamma` at until the minimum value is reached. The frequency of change is defined by the `step` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.update({\n",
    "     \"learning_rate\": {\n",
    "        \"start\":0.0001,         \n",
    "        \"min\": 0.000001,\n",
    "        \"gamma\": 0.95,\n",
    "        \"step\": 1\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the assembly of the second block of the input `JSON`. This can be added to the previously initialised configuration and written out as a `JSON` file to be passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the configuration\n",
    "configuration.update({\n",
    "    \"parameters\": parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a JSON file\n",
    "configuration_JSON_path = os.path.join(output_dir, \"TL_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "Please note this training might take days with the suggested dataset and the number of epochs.\n",
    "\n",
    "Execute in jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!python {project_directory}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute in command line:\n",
    "```\n",
    "# activate environment\n",
    "$ conda activate lib-invent\n",
    "\n",
    "# execute in command line\n",
    "$ python <project_directory>/input.py <configuration_JSON_path>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the results\n",
    "`tensorboard` is used for logging of all Lib-INVENT runs. The relevant logs are saved to the directory specified by the `logging_path` argument. \n",
    "\n",
    "To open and run tensorboard from the command line:\n",
    "\n",
    "```\n",
    "# go to the root folder of the output\n",
    "$ cd output_dir\n",
    "\n",
    "$ conda activate lib-invent\n",
    "\n",
    "# start tensorboard\n",
    "$ tensorboard --logdir \"output_dir/run.log\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
